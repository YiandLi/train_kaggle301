{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "Y7BduhbrV7mm"
   },
   "outputs": [],
   "source": [
    "#!unzip learning-equality-curriculum-recommendations.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lyfn8McqUEBQ"
   },
   "source": [
    "## CV Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "XfVCwUiETLWX",
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedGroupKFold\n",
    "from multiprocesspandas import applyparallel\n",
    "import regex as re\n",
    "import string\n",
    "import time\n",
    "import math\n",
    "from sklearn.metrics import f1_score\n",
    "from torch.optim import Adam, SGD, AdamW\n",
    "from transformers import get_linear_schedule_with_warmup, get_cosine_schedule_with_warmup, DataCollatorWithPadding,BertTokenizer,AutoModel,AdamW,AutoConfig, AutoModelForSequenceClassification, AutoTokenizer\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim import lr_scheduler\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "import copy\n",
    "import torch.nn as nn\n",
    "import os\n",
    "import json\n",
    "import gc\n",
    "import random\n",
    "from torch.cuda.amp import autocast, GradScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "_x264mcXT-5R",
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "N_SPLITS = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "CbJxrkWxxWti",
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "class CFG:\n",
    "    input_path = r'/root/kaggle/input_dir/'\n",
    "    model_path = r'/root/kaggle/input_dir/model/xlm-roberta-base' \n",
    "    scheduler = 'cosine'  # ['linear', 'cosine']\n",
    "    batch_scheduler = True\n",
    "    num_cycles = 0.5  # 1.5\n",
    "    num_warmup_steps = 0\n",
    "    max_input_length = 300\n",
    "    epochs = 5  # 5\n",
    "    encoder_lr = 20e-6\n",
    "    decoder_lr = 1e-3\n",
    "    min_lr = 0.5e-6\n",
    "    eps = 1e-6\n",
    "    betas = (0.9, 0.999)\n",
    "    weight_decay = 0\n",
    "    num_fold = 5\n",
    "    batch_size = 5\n",
    "    seed = 1006\n",
    "    OUTPUT_DIR = '/root/kaggle/output_dir/'\n",
    "    num_workers = 2\n",
    "    device='cuda'\n",
    "    print_freq = 100\n",
    "    apex=False\n",
    "    start_awp_epoch = 2 # 开始AWP epoch\n",
    "    adv_lr = 1e-5 # AWP学习率\n",
    "    adv_eps = 1e-3 # AWP epsilon\n",
    "    adv_step = 1 # AWP step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "KpzDtQBUUCd1",
    "notebookRunGroups": {
     "groupValue": ""
    }
   },
   "outputs": [],
   "source": [
    "topic_df = pd.read_csv(CFG.input_path + r'topics.csv')\n",
    "content_df = pd.read_csv(CFG.input_path + r'content.csv')\n",
    "corr_df = pd.read_csv(CFG.input_path + r'correlations.csv')\n",
    "# topic_df = topic_df.rename(columns={'id': 'topic_id'}).merge(corr_df)\n",
    "topic_df_non_source = topic_df[topic_df['category']!='source'].reset_index(drop=True)\n",
    "topic_df_non_source['stratify'] = topic_df_non_source['category'] + \\\n",
    "topic_df_non_source['language'] + topic_df_non_source['description'].apply(lambda x: str(isinstance(x, str))) + \\\n",
    "topic_df_non_source['has_content'].apply(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_lvM_JZuUnoT",
    "notebookRunGroups": {
     "groupValue": ""
    },
    "outputId": "ee34b1d5-16eb-426c-aa65-5af83917a603"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/sklearn/model_selection/_split.py:880: UserWarning: The least populated class in y has only 3 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "kf = StratifiedGroupKFold(n_splits=N_SPLITS)\n",
    "folds = list(kf.split(topic_df_non_source, y=topic_df_non_source[\"stratify\"], groups=topic_df_non_source[\"channel\"]))\n",
    "topic_df_non_source['fold'] = -1\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(folds):\n",
    "    topic_df_non_source.loc[val_idx, \"fold\"] = fold\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "O6YY6bJkUt5H",
    "notebookRunGroups": {
     "groupValue": ""
    }
   },
   "outputs": [],
   "source": [
    "fold_df =  topic_df.merge(topic_df_non_source[['id', 'fold']], on='id', how='left').reset_index(drop=True)[['id', 'fold']].fillna(-1).rename(columns={'id': 'topic_id'})\n",
    "fold_df['fold'] = fold_df['fold'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "e9L5F7uqWhpl",
    "notebookRunGroups": {
     "groupValue": ""
    }
   },
   "outputs": [],
   "source": [
    "corr_df['content_ids'] = corr_df['content_ids'].apply(lambda x:x.split())\n",
    "corr_df = corr_df.explode('content_ids').reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": ""
    }
   },
   "outputs": [],
   "source": [
    "topic_df = topic_df.fillna('')\n",
    "topic_df['topic_full_text'] =  topic_df['title'] + ' [SEP] ' + topic_df['description']\n",
    "topic_df = topic_df[['id', 'topic_full_text', 'language']]\n",
    "df = corr_df.merge(topic_df, left_on='topic_id', right_on='id', how='left')\n",
    "df = df[['topic_id','content_ids','topic_full_text','language']]\n",
    "df = df.rename(columns={'language':'topic_language'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "DA20jcVaXkkP",
    "notebookRunGroups": {
     "groupValue": ""
    }
   },
   "outputs": [],
   "source": [
    "content_df = content_df.fillna('')\n",
    "\n",
    "content_df['content_full_text'] =  content_df['title'] + ' [SEP] ' + content_df['description'] + ' [SEP] ' + content_df['text']\n",
    "content_df = content_df[['id', 'content_full_text', 'language']]\n",
    "df = df.merge(content_df, left_on='content_ids', right_on='id', how='left')\n",
    "df = df.rename(columns={'language':'content_language'})\n",
    "df['label'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic_id</th>\n",
       "      <th>content_ids</th>\n",
       "      <th>topic_full_text</th>\n",
       "      <th>topic_language</th>\n",
       "      <th>id</th>\n",
       "      <th>content_full_text</th>\n",
       "      <th>content_language</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>t_00004da3a1b2</td>\n",
       "      <td>c_1108dd0c7a5d</td>\n",
       "      <td>Откриването на резисторите [SEP] Изследване на...</td>\n",
       "      <td>bg</td>\n",
       "      <td>c_1108dd0c7a5d</td>\n",
       "      <td>Молив като резистор [SEP] Моливът причинява пр...</td>\n",
       "      <td>bg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>t_00004da3a1b2</td>\n",
       "      <td>c_376c5a8eb028</td>\n",
       "      <td>Откриването на резисторите [SEP] Изследване на...</td>\n",
       "      <td>bg</td>\n",
       "      <td>c_376c5a8eb028</td>\n",
       "      <td>Да чуем променливото съпротивление [SEP] Тук ч...</td>\n",
       "      <td>bg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>t_00004da3a1b2</td>\n",
       "      <td>c_5bc0e1e2cba0</td>\n",
       "      <td>Откриването на резисторите [SEP] Изследване на...</td>\n",
       "      <td>bg</td>\n",
       "      <td>c_5bc0e1e2cba0</td>\n",
       "      <td>Променлив резистор (реостат) с графит от молив...</td>\n",
       "      <td>bg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>t_00004da3a1b2</td>\n",
       "      <td>c_76231f9d0b5e</td>\n",
       "      <td>Откриването на резисторите [SEP] Изследване на...</td>\n",
       "      <td>bg</td>\n",
       "      <td>c_76231f9d0b5e</td>\n",
       "      <td>Последователно свързване на галваничен елемент...</td>\n",
       "      <td>bg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>t_00068291e9a4</td>\n",
       "      <td>c_639ea2ef9c95</td>\n",
       "      <td>Entradas e saídas de uma função [SEP] Entenda ...</td>\n",
       "      <td>pt</td>\n",
       "      <td>c_639ea2ef9c95</td>\n",
       "      <td>Dados e resultados de funções: gráficos [SEP] ...</td>\n",
       "      <td>pt</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         topic_id     content_ids  \\\n",
       "0  t_00004da3a1b2  c_1108dd0c7a5d   \n",
       "1  t_00004da3a1b2  c_376c5a8eb028   \n",
       "2  t_00004da3a1b2  c_5bc0e1e2cba0   \n",
       "3  t_00004da3a1b2  c_76231f9d0b5e   \n",
       "4  t_00068291e9a4  c_639ea2ef9c95   \n",
       "\n",
       "                                     topic_full_text topic_language  \\\n",
       "0  Откриването на резисторите [SEP] Изследване на...             bg   \n",
       "1  Откриването на резисторите [SEP] Изследване на...             bg   \n",
       "2  Откриването на резисторите [SEP] Изследване на...             bg   \n",
       "3  Откриването на резисторите [SEP] Изследване на...             bg   \n",
       "4  Entradas e saídas de uma função [SEP] Entenda ...             pt   \n",
       "\n",
       "               id                                  content_full_text  \\\n",
       "0  c_1108dd0c7a5d  Молив като резистор [SEP] Моливът причинява пр...   \n",
       "1  c_376c5a8eb028  Да чуем променливото съпротивление [SEP] Тук ч...   \n",
       "2  c_5bc0e1e2cba0  Променлив резистор (реостат) с графит от молив...   \n",
       "3  c_76231f9d0b5e  Последователно свързване на галваничен елемент...   \n",
       "4  c_639ea2ef9c95  Dados e resultados de funções: gráficos [SEP] ...   \n",
       "\n",
       "  content_language  label  \n",
       "0               bg      1  \n",
       "1               bg      1  \n",
       "2               bg      1  \n",
       "3               bg      1  \n",
       "4               pt      1  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "NhAgbgLbq4SM",
    "notebookRunGroups": {
     "groupValue": ""
    }
   },
   "outputs": [],
   "source": [
    "df = df[['topic_id', 'topic_full_text', 'content_full_text', 'label']]\n",
    "df = pd.concat([df])\n",
    "df = df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "SoS2ECSO7hfd",
    "notebookRunGroups": {
     "groupValue": ""
    }
   },
   "outputs": [],
   "source": [
    "df = df.merge(fold_df, left_on='topic_id', right_on='topic_id', how='left')\n",
    "df = df[['topic_full_text', 'content_full_text', 'label' ,'fold']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "flmIFIdcEwkZ",
    "notebookRunGroups": {
     "groupValue": ""
    },
    "outputId": "70deaf8e-bae0-4110-a9ad-27dbe45a21ab"
   },
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    for punctuation in list(string.punctuation): text = text.replace(punctuation, '')\n",
    "    output = re.sub('\\r+', ' ', text)\n",
    "    output = re.sub('\\n+', ' ', output)\n",
    "    \n",
    "    return output\n",
    "df['topic_full_text'] = df['topic_full_text'].apply(lambda x:clean_text(x))\n",
    "df['content_full_text'] = df['content_full_text'].apply(lambda x:clean_text(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "OP_LxmnFb4ry",
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "# df.to_csv(CFG.OUTPUT_DIR + r'train_folds.csv', index=None)\n",
    "df = pd.read_csv(CFG.OUTPUT_DIR + r'train_folds.csv')\n",
    "df = df[df['fold'].isin([0, 1, 2, 3, 4])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4jsi4Pr8wWqM"
   },
   "source": [
    "## create CFG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "safR828DxavN",
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "def seed_everything(seed=42):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "seed_everything(CFG.seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "j1-oQIqpwalb",
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "class TrainDataset(Dataset):\n",
    "    def __init__(self,df,tokenizer):\n",
    "        self.topic = df['topic_full_text'].values\n",
    "        self.content = df['content_full_text'].values\n",
    "        self.label = df['label'].values\n",
    "        self.tokenizer = tokenizer\n",
    "        self.sep_token = tokenizer.sep_token\n",
    "    def __len__(self):\n",
    "        return len(self.topic)\n",
    "    def __getitem__(self, item):\n",
    "        topic = self.topic[item].replace('[SEP]', self.sep_token)\n",
    "        content = self.content[item].replace('[SEP]', self.sep_token)\n",
    "        label = int(self.label[item])\n",
    "\n",
    "        \n",
    "        inputs_topic = self.tokenizer(topic, truncation=True, max_length=CFG.max_input_length, padding='max_length')\n",
    "        inputs_content = self.tokenizer(content, truncation=True, max_length=CFG.max_input_length, padding='max_length')\n",
    "        return torch.as_tensor(inputs_topic['input_ids'], dtype=torch.long), \\\n",
    "            torch.as_tensor(inputs_topic['attention_mask'], dtype=torch.long), \\\n",
    "            torch.as_tensor(inputs_content['input_ids'], dtype=torch.long), \\\n",
    "            torch.as_tensor(inputs_content['attention_mask'], dtype=torch.long), \\\n",
    "            torch.as_tensor(label, dtype=torch.float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XnCXK1kYzPCo"
   },
   "source": [
    "## build model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "i0w2WY_OzLeC",
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModel, AutoConfig\n",
    "from transformers.modeling_outputs import SequenceClassifierOutput\n",
    "\n",
    "class Custom_Bert_Simple(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.base = AutoModel.from_pretrained(CFG.model_path)\n",
    "        self.config = AutoConfig.from_pretrained(CFG.model_path)\n",
    "        self.linear = nn.Linear(self.config.hidden_size*3, 1)\n",
    "\n",
    "    def forward(self,\n",
    "        topic_input_ids,\n",
    "        content_input_ids,\n",
    "        topic_attention_mask=None,\n",
    "        content_attention_mask=None, \n",
    "        labels=None):\n",
    "        topic_output = self.base(input_ids=topic_input_ids,attention_mask=topic_attention_mask)\n",
    "        topic_output = topic_output.last_hidden_state\n",
    "        topic_output = torch.mean(topic_output, dim=1)\n",
    "\n",
    "        content_output = self.base(input_ids=content_input_ids,attention_mask=content_attention_mask)\n",
    "        content_output = content_output.last_hidden_state\n",
    "        content_output = torch.mean(content_output, dim=1)\n",
    "\n",
    "        diff = torch.abs(topic_output-content_output)\n",
    "\n",
    "        sentence_embedding = torch.cat([topic_output, content_output, diff], 1)\n",
    "\n",
    "        output = self.linear(sentence_embedding)\n",
    "        \n",
    "        loss = None\n",
    "        if labels is not None:\n",
    "            loss = F.binary_cross_entropy_with_logits(output.view(-1), labels.view(-1))\n",
    "        \n",
    "        return loss, sentence_embedding\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xB4GaI9fDzt1"
   },
   "source": [
    "## build logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "R3SPEdriD2lE",
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "\n",
    "def asMinutes(s):\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "\n",
    "def timeSince(since, percent):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    es = s / (percent)\n",
    "    rs = es - s\n",
    "    return '%s (remain %s)' % (asMinutes(s), asMinutes(rs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "B6VVH3jSEYie",
    "notebookRunGroups": {
     "groupValue": "1"
    },
    "outputId": "b0d4793c-ef1e-4623-b4f7-9a4f6ce628cd"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "===============lr_2e-05===============\n",
      "===============seed_1006===============\n",
      "===============total_epochs_5===============\n",
      "===============num_warmup_steps_0===============\n"
     ]
    }
   ],
   "source": [
    "def get_logger(filename=CFG.OUTPUT_DIR+ 'train'):\n",
    "    from logging import getLogger, INFO, StreamHandler, FileHandler, Formatter\n",
    "    logger = getLogger(__name__)\n",
    "    logger.setLevel(INFO)\n",
    "    handler1 = StreamHandler()\n",
    "    handler1.setFormatter(Formatter(\"%(message)s\"))\n",
    "    handler2 = FileHandler(filename=f\"{filename}.log\")\n",
    "    handler2.setFormatter(Formatter(\"%(message)s\"))\n",
    "    logger.addHandler(handler1)\n",
    "    logger.addHandler(handler2)\n",
    "    return logger\n",
    "\n",
    "LOGGER = get_logger()\n",
    "LOGGER.info('===============lr_{}==============='.format(CFG.encoder_lr))\n",
    "LOGGER.info('===============seed_{}==============='.format(CFG.seed))\n",
    "LOGGER.info('===============total_epochs_{}==============='.format(CFG.epochs))\n",
    "LOGGER.info('===============num_warmup_steps_{}==============='.format(CFG.num_warmup_steps))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FQDtzCGV5S0B"
   },
   "source": [
    "## build pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 对抗训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "class FGM():\n",
    "    def __init__(self, model):\n",
    "        self.model = model\n",
    "        self.backup = {}\n",
    " \n",
    "    def attack(self, epsilon=.01, emb_name='word_embedding'):\n",
    "        # emb_name这个参数要换成你模型中embedding的参数名\n",
    "        for name, param in self.model.named_parameters():\n",
    "            if param.requires_grad and emb_name in name:\n",
    "                self.backup[name] = param.data.clone()\n",
    "                norm = torch.norm(param.grad)\n",
    "                if norm != 0 and not torch.isnan(norm):\n",
    "                    r_at = epsilon * param.grad / norm\n",
    "                    param.data.add_(r_at)\n",
    " \n",
    "    def restore(self, emb_name='word_embedding'):\n",
    "        # emb_name这个参数要换成你模型中embedding的参数名\n",
    "        for name, param in self.model.named_parameters():\n",
    "            if param.requires_grad and emb_name in name:\n",
    "                assert name in self.backup\n",
    "                param.data = self.backup[name]\n",
    "        self.backup = {}\n",
    "\n",
    "def train_fn_adv(train_loader, model, optimizer, epoch, scheduler, device):\n",
    "    model.train()\n",
    "    losses = AverageMeter()\n",
    "    start = end = time.time()\n",
    "    global_step = 0\n",
    "    fgm = FGM(model)\n",
    "    for step, batch in enumerate(train_loader):\n",
    "        batch = [i.to(device) for i in batch]\n",
    "        topic_input_ids, topic_attention_mask, content_input_ids, content_attention_mask, label = batch\n",
    "        batch_size = label.size(0)\n",
    "        loss = model(topic_input_ids, content_input_ids, topic_attention_mask, content_attention_mask, label)[0]\n",
    "        losses.update(loss.item(), batch_size)\n",
    "        loss.backward()\n",
    "        grad_norm = torch.nn.utils.clip_grad_norm_(model.parameters(), 500)\n",
    "        # 对抗训练\n",
    "        fgm.attack() # embedding被修改了\n",
    "        # optimizer.zero_grad() # 如果不想累加梯度，就把这里的注释取消\n",
    "        loss_adv =model(topic_input_ids, content_input_ids, topic_attention_mask, content_attention_mask, label)[0]\n",
    "        loss_adv.backward() # 反向传播，在正常的grad基础上，累加对抗训练的梯度\n",
    "        fgm.restore() # 恢复Embedding的参数\n",
    "        # 梯度下降，更新参数\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        global_step += 1\n",
    "        scheduler.step()\n",
    "        end = time.time()\n",
    "        if step % CFG.print_freq == 0 or step == (len(train_loader) - 1):\n",
    "            print('Epoch: [{0}][{1}/{2}] '\n",
    "                  'Elapsed {remain:s} '\n",
    "                  'Loss: {loss.val:.4f}({loss.avg:.4f}) '\n",
    "                  'Grad: {grad_norm:.4f}  '\n",
    "                  'LR: {lr:.8f}  '\n",
    "                  .format(epoch + 1, step, len(train_loader),\n",
    "                          remain=timeSince(start, float(step + 1) / len(train_loader)),\n",
    "                          loss=losses,\n",
    "                          grad_norm=grad_norm,\n",
    "                          lr=scheduler.get_lr()[0]))\n",
    "    return losses.avg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## R-drop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "def compute_kl_loss(p, q, pad_mask=None):\n",
    "    \n",
    "    p_loss = F.kl_div(F.log_softmax(p, dim=-1), F.softmax(q, dim=-1), reduction='none') # b, 36\n",
    "    q_loss = F.kl_div(F.log_softmax(q, dim=-1), F.softmax(p, dim=-1), reduction='none')\n",
    "    \n",
    "    # pad_mask is for seq-level tasks\n",
    "    if pad_mask is not None:\n",
    "        p_loss.masked_fill_(pad_mask, 0.)\n",
    "        q_loss.masked_fill_(pad_mask, 0.)\n",
    "\n",
    "    # You can choose whether to use function \"sum\" and \"mean\" depending on your task\n",
    "    p_loss = p_loss.sum()\n",
    "    q_loss = q_loss.sum()\n",
    "\n",
    "    loss = (p_loss + q_loss) / 2\n",
    "    return loss\n",
    "\n",
    "def train_fn_r_drop(train_loader, model, optimizer, epoch, scheduler, device):\n",
    "    model.train()\n",
    "    losses = AverageMeter()\n",
    "    start = end = time.time()\n",
    "    global_step = 0\n",
    "    for step, batch in enumerate(train_loader):\n",
    "        batch = [i.to(device) for i in batch]\n",
    "        topic_input_ids, topic_attention_mask, content_input_ids, content_attention_mask, label = batch\n",
    "        batch_size = label.size(0)\n",
    "        loss_0,  = model(topic_input_ids, content_input_ids, topic_attention_mask, content_attention_mask, label) #\n",
    "        loss_0 = output_0.loss\n",
    "        logits_0 = output_0.logits # batch , num_labels\n",
    "        output_1 = model(input_ids, mask, labels=label)\n",
    "        loss_1 = output_1.loss\n",
    "        logits_1 = output_1.logits\n",
    "        ce_loss = 0.5 * (loss_0 + loss_1)\n",
    "        kl_loss = compute_kl_loss(logits_0, logits_1)\n",
    "        loss = ce_loss + 0.5 * kl_loss\n",
    "        losses.update(loss.item(), batch_size)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        grad_norm = torch.nn.utils.clip_grad_norm_(model.parameters(), 500)\n",
    "        optimizer.step()\n",
    "        global_step += 1\n",
    "        scheduler.step()\n",
    "        end = time.time()\n",
    "        if step % CFG.print_freq == 0 or step == (len(train_loader) - 1):\n",
    "            print('Epoch: [{0}][{1}/{2}] '\n",
    "                  'Elapsed {remain:s} '\n",
    "                  'Loss: {loss.val:.4f}({loss.avg:.4f}) '\n",
    "                  'Grad: {grad_norm:.4f}  '\n",
    "                  'LR: {lr:.8f}  '\n",
    "                  .format(epoch + 1, step, len(train_loader),\n",
    "                          remain=timeSince(start, float(step + 1) / len(train_loader)),\n",
    "                          loss=losses,\n",
    "                          grad_norm=grad_norm,\n",
    "                          lr=scheduler.get_lr()[0]))\n",
    "    return losses.avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "S6Pg-_675VB2",
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "def train_fn(train_loader, model, optimizer, epoch, scheduler, device):\n",
    "    model.train()\n",
    "    losses = AverageMeter()\n",
    "    start = end = time.time()\n",
    "    global_step = 0\n",
    "    for step, batch in enumerate(train_loader):\n",
    "        batch = [i.to(device) for i in batch]\n",
    "        topic_input_ids, topic_attention_mask, content_input_ids, content_attention_mask, label = batch\n",
    "        batch_size = label.size(0)\n",
    "        loss = model(topic_input_ids, content_input_ids, topic_attention_mask, content_attention_mask, label)[0]\n",
    "        losses.update(loss.item(), batch_size)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        grad_norm = torch.nn.utils.clip_grad_norm_(model.parameters(), 50000)\n",
    "        optimizer.step()\n",
    "        global_step += 1\n",
    "        scheduler.step()\n",
    "        end = time.time()\n",
    "        if step % CFG.print_freq == 0 or step == (len(train_loader) - 1):\n",
    "            print('Epoch: [{0}][{1}/{2}] '\n",
    "                  'Elapsed {remain:s} '\n",
    "                  'Loss: {loss.val:.4f}({loss.avg:.4f}) '\n",
    "                  'Grad: {grad_norm:.4f}  '\n",
    "                  'LR: {lr:.8f}  '\n",
    "                  .format(epoch + 1, step, len(train_loader),\n",
    "                          remain=timeSince(start, float(step + 1) / len(train_loader)),\n",
    "                          loss=losses,\n",
    "                          grad_norm=grad_norm,\n",
    "                          lr=scheduler.get_lr()[0]))\n",
    "    return losses.avg\n",
    "\n",
    "\n",
    "def valid_fn(valid_loader, model, device):\n",
    "    losses = AverageMeter()\n",
    "    model.eval()\n",
    "    preds = []\n",
    "    labels = []\n",
    "    start = end = time.time()\n",
    "    for step, batch in enumerate(valid_loader):\n",
    "        label = batch[2].to(device)\n",
    "        mask = batch[1].to(device)\n",
    "        input_ids = batch[0].to(device)\n",
    "        batch_size = label.size(0)\n",
    "        with torch.no_grad():\n",
    "            output = model(input_ids, mask, labels=label)\n",
    "        loss = output.loss[0]\n",
    "        y_preds = output.logits.argmax(dim=-1)\n",
    "        losses.update(loss.item(), batch_size)\n",
    "        preds.append(y_preds.to('cpu').numpy())\n",
    "        labels.append(label.to('cpu').numpy())\n",
    "        end = time.time()\n",
    "        if step % CFG.print_freq == 0 or step == (len(valid_loader) - 1):\n",
    "            print('EVAL: [{0}/{1}] '\n",
    "                  'Elapsed {remain:s} '\n",
    "                  'Loss: {loss.val:.4f}({loss.avg:.4f}) '\n",
    "                  .format(step, len(valid_loader),\n",
    "                          loss=losses,\n",
    "                          remain=timeSince(start, float(step + 1) / len(valid_loader))))\n",
    "    predictions = np.concatenate(preds)\n",
    "    labels = np.concatenate(labels)\n",
    "    #print(predictions)\n",
    "    return losses.avg, predictions, labels\n",
    "\n",
    "def train_loop(fold, model, train_dataset, valid_dataset):\n",
    "    LOGGER.info(f\"========== training ==========\")\n",
    "\n",
    "    # ====================================================\n",
    "    # loader\n",
    "    # ====================================================\n",
    "\n",
    "    train_loader = DataLoader(train_dataset,\n",
    "                              batch_size=CFG.batch_size,\n",
    "                              shuffle=True,\n",
    "                              num_workers=CFG.num_workers, pin_memory=True, drop_last=True)\n",
    "    valid_loader = DataLoader(valid_dataset,\n",
    "                              batch_size=CFG.batch_size * 2,\n",
    "                              shuffle=False,\n",
    "                              num_workers=CFG.num_workers, pin_memory=True, drop_last=False)\n",
    "\n",
    "    # ====================================================\n",
    "    # model & optimizer\n",
    "    # ====================================================\n",
    "    #model = Custom_Bert_Simple()\n",
    "    #model = AutoModelForSequenceClassification.from_pretrained(CFG.model_path, num_labels=1)\n",
    "    model.to(CFG.device)\n",
    "\n",
    "    def get_optimizer_params(model, encoder_lr, decoder_lr, weight_decay=0.0):\n",
    "        param_optimizer = list(model.named_parameters())\n",
    "        no_decay = [\"bias\", \"LayerNorm.bias\", \"LayerNorm.weight\"]\n",
    "        optimizer_parameters = [\n",
    "            {'params': [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)],\n",
    "             'lr': encoder_lr, 'weight_decay': weight_decay},\n",
    "            {'params': [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)],\n",
    "             'lr': encoder_lr, 'weight_decay': 0.0},\n",
    "        ]\n",
    "        return optimizer_parameters\n",
    "\n",
    "    def get_optimizer(model):\n",
    "\n",
    "        no_decay = ['bias', 'LayerNorm.bias', 'LayerNorm.weight']\n",
    "        optimizer_parameters = [\n",
    "            {'params': [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)],\n",
    "                'lr': CFG.encoder_lr, 'weight_decay': CFG.weight_decay},\n",
    "            {'params': [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)],\n",
    "                'lr': CFG.encoder_lr, 'weight_decay': 0.0}\n",
    "            \n",
    "        ]\n",
    "        optimizer = AdamW(optimizer_parameters, lr = CFG.encoder_lr, eps = CFG.eps, betas = CFG.betas)\n",
    "        return optimizer\n",
    "\n",
    "    \n",
    "    optimizer = get_optimizer(model)\n",
    "\n",
    "    # ====================================================\n",
    "    # scheduler\n",
    "    # ====================================================\n",
    "    def get_scheduler(cfg, optimizer, num_train_steps):\n",
    "        cfg.num_warmup_steps = cfg.num_warmup_steps * num_train_steps\n",
    "        if cfg.scheduler == 'linear':\n",
    "            scheduler = get_linear_schedule_with_warmup(\n",
    "                optimizer, num_warmup_steps=cfg.num_warmup_steps, num_training_steps=num_train_steps\n",
    "            )\n",
    "        elif cfg.scheduler == 'cosine':\n",
    "            scheduler = get_cosine_schedule_with_warmup(\n",
    "                optimizer, num_warmup_steps=cfg.num_warmup_steps, num_training_steps=num_train_steps,\n",
    "                num_cycles=cfg.num_cycles\n",
    "            )\n",
    "        return scheduler\n",
    "\n",
    "    num_train_steps = int(len(train_dataset) / CFG.batch_size * CFG.epochs)\n",
    "    scheduler = get_scheduler(CFG, optimizer, num_train_steps)\n",
    "\n",
    "    # ====================================================\n",
    "    # loop\n",
    "    # ====================================================\n",
    "    # criterion = torch.nn.CrossEntropyLoss(ignore_index=- 1)\n",
    "\n",
    "    # criterion = LabelSmoothingLoss()\n",
    "    best_score = float('inf')\n",
    "\n",
    "    for epoch in range(CFG.epochs):\n",
    "\n",
    "        start_time = time.time()\n",
    "\n",
    "        # train\n",
    "        #avg_loss = train_fn_awp(train_loader, model, optimizer, epoch, scheduler, CFG.device)\n",
    "        \n",
    "        avg_loss = train_fn(train_loader, model, optimizer, epoch, scheduler, CFG.device)\n",
    "        # eval\n",
    "        #avg_val_loss, predictions, valid_labels = valid_fn(valid_loader, model, CFG.device)\n",
    "\n",
    "        # scoring\n",
    "        #score = get_score(predictions, valid_labels)\n",
    "\n",
    "        elapsed = time.time() - start_time\n",
    "\n",
    "        LOGGER.info(\n",
    "            f'Epoch {epoch + 1} - avg_train_loss: {avg_loss:.4f}  time: {elapsed:.0f}s')\n",
    "        #LOGGER.info(f'Epoch {epoch + 1} - Score: {score:.4f}')\n",
    "\n",
    "\n",
    "        if best_score > avg_loss:\n",
    "            best_score = avg_loss\n",
    "            #best_predictions = predictions\n",
    "            LOGGER.info(f'Epoch {epoch + 1} - Save Best Score: {best_score:.4f} Model')\n",
    "            torch.save(model.state_dict(),\n",
    "                       CFG.OUTPUT_DIR + \"{}_best{}.pth\".format(CFG.model_path.replace('/', '_'),fold))\n",
    "\n",
    "\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "    del scheduler, optimizer, model\n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kazL85iWEb5W",
    "notebookRunGroups": {
     "groupValue": "1"
    },
    "outputId": "5953d979-3e8b-4911-8876-834e16ceb357"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at /root/kaggle/input_dir/model/xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.bias', 'lm_head.decoder.weight', 'lm_head.layer_norm.weight', 'lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "========== training ==========\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/torch/optim/lr_scheduler.py:249: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1][0/16626] Elapsed 0m 1s (remain 359m 42s) Loss: 0.5809(0.5809) Grad: 11.3352  LR: 0.00002000  \n",
      "Epoch: [1][100/16626] Elapsed 0m 17s (remain 48m 46s) Loss: 0.0016(0.0551) Grad: 0.0491  LR: 0.00002000  \n",
      "Epoch: [1][200/16626] Elapsed 0m 34s (remain 47m 10s) Loss: 0.0005(0.0282) Grad: 0.0142  LR: 0.00002000  \n",
      "Epoch: [1][300/16626] Elapsed 0m 51s (remain 46m 29s) Loss: 0.0007(0.0191) Grad: 0.0427  LR: 0.00002000  \n",
      "Epoch: [1][400/16626] Elapsed 1m 8s (remain 45m 58s) Loss: 0.0003(0.0144) Grad: 0.0097  LR: 0.00002000  \n",
      "Epoch: [1][500/16626] Elapsed 1m 25s (remain 45m 36s) Loss: 0.0003(0.0116) Grad: 0.0081  LR: 0.00002000  \n",
      "Epoch: [1][600/16626] Elapsed 1m 41s (remain 45m 17s) Loss: 0.0003(0.0097) Grad: 0.0078  LR: 0.00002000  \n",
      "Epoch: [1][700/16626] Elapsed 1m 58s (remain 44m 59s) Loss: 0.0003(0.0083) Grad: 0.0135  LR: 0.00002000  \n",
      "Epoch: [1][800/16626] Elapsed 2m 15s (remain 44m 42s) Loss: 0.0001(0.0073) Grad: 0.0061  LR: 0.00002000  \n",
      "Epoch: [1][900/16626] Elapsed 2m 32s (remain 44m 26s) Loss: 0.0001(0.0065) Grad: 0.0041  LR: 0.00001999  \n",
      "Epoch: [1][1000/16626] Elapsed 2m 49s (remain 44m 10s) Loss: 0.0001(0.0059) Grad: 0.0043  LR: 0.00001999  \n",
      "Epoch: [1][1100/16626] Elapsed 3m 6s (remain 43m 55s) Loss: 0.0001(0.0054) Grad: 0.0038  LR: 0.00001999  \n",
      "Epoch: [1][1200/16626] Elapsed 3m 23s (remain 43m 39s) Loss: 0.0000(0.0049) Grad: 0.0017  LR: 0.00001999  \n",
      "Epoch: [1][1300/16626] Elapsed 3m 41s (remain 43m 23s) Loss: 0.0000(0.0045) Grad: 0.0012  LR: 0.00001999  \n",
      "Epoch: [1][1400/16626] Elapsed 3m 58s (remain 43m 7s) Loss: 0.0001(0.0042) Grad: 0.0021  LR: 0.00001999  \n",
      "Epoch: [1][1500/16626] Elapsed 4m 15s (remain 42m 51s) Loss: 0.0001(0.0039) Grad: 0.0021  LR: 0.00001998  \n",
      "Epoch: [1][1600/16626] Elapsed 4m 32s (remain 42m 35s) Loss: 0.0000(0.0037) Grad: 0.0010  LR: 0.00001998  \n",
      "Epoch: [1][1700/16626] Elapsed 4m 49s (remain 42m 19s) Loss: 0.0001(0.0035) Grad: 0.0016  LR: 0.00001998  \n",
      "Epoch: [1][1800/16626] Elapsed 5m 6s (remain 42m 2s) Loss: 0.0001(0.0033) Grad: 0.0015  LR: 0.00001998  \n",
      "Epoch: [1][1900/16626] Elapsed 5m 23s (remain 41m 46s) Loss: 0.0000(0.0031) Grad: 0.0021  LR: 0.00001997  \n",
      "Epoch: [1][2000/16626] Elapsed 5m 40s (remain 41m 30s) Loss: 0.0000(0.0030) Grad: 0.0012  LR: 0.00001997  \n",
      "Epoch: [1][2100/16626] Elapsed 5m 57s (remain 41m 13s) Loss: 0.0000(0.0028) Grad: 0.0008  LR: 0.00001997  \n",
      "Epoch: [1][2200/16626] Elapsed 6m 14s (remain 40m 57s) Loss: 0.0000(0.0027) Grad: 0.0010  LR: 0.00001997  \n",
      "Epoch: [1][2300/16626] Elapsed 6m 32s (remain 40m 40s) Loss: 0.0000(0.0026) Grad: 0.0008  LR: 0.00001996  \n",
      "Epoch: [1][2400/16626] Elapsed 6m 49s (remain 40m 24s) Loss: 0.0000(0.0025) Grad: 0.0011  LR: 0.00001996  \n",
      "Epoch: [1][2500/16626] Elapsed 7m 6s (remain 40m 7s) Loss: 0.0000(0.0024) Grad: 0.0008  LR: 0.00001996  \n",
      "Epoch: [1][2600/16626] Elapsed 7m 23s (remain 39m 50s) Loss: 0.0000(0.0023) Grad: 0.0007  LR: 0.00001995  \n",
      "Epoch: [1][2700/16626] Elapsed 7m 40s (remain 39m 34s) Loss: 0.0000(0.0022) Grad: 0.0008  LR: 0.00001995  \n",
      "Epoch: [1][2800/16626] Elapsed 7m 57s (remain 39m 17s) Loss: 0.0000(0.0021) Grad: 0.0004  LR: 0.00001994  \n",
      "Epoch: [1][2900/16626] Elapsed 8m 14s (remain 39m 0s) Loss: 0.0000(0.0021) Grad: 0.0011  LR: 0.00001994  \n",
      "Epoch: [1][3000/16626] Elapsed 8m 31s (remain 38m 43s) Loss: 0.0000(0.0020) Grad: 0.0006  LR: 0.00001994  \n",
      "Epoch: [1][3100/16626] Elapsed 8m 48s (remain 38m 26s) Loss: 0.0000(0.0019) Grad: 0.0006  LR: 0.00001993  \n",
      "Epoch: [1][3200/16626] Elapsed 9m 6s (remain 38m 10s) Loss: 0.0000(0.0019) Grad: 0.0006  LR: 0.00001993  \n",
      "Epoch: [1][3300/16626] Elapsed 9m 23s (remain 37m 53s) Loss: 0.0000(0.0018) Grad: 0.0006  LR: 0.00001992  \n",
      "Epoch: [1][3400/16626] Elapsed 9m 40s (remain 37m 36s) Loss: 0.0000(0.0018) Grad: 0.0005  LR: 0.00001992  \n",
      "Epoch: [1][3500/16626] Elapsed 9m 57s (remain 37m 19s) Loss: 0.0000(0.0017) Grad: 0.0006  LR: 0.00001991  \n",
      "Epoch: [1][3600/16626] Elapsed 10m 14s (remain 37m 2s) Loss: 0.0000(0.0017) Grad: 0.0003  LR: 0.00001991  \n",
      "Epoch: [1][3700/16626] Elapsed 10m 31s (remain 36m 45s) Loss: 0.0000(0.0016) Grad: 0.0003  LR: 0.00001990  \n",
      "Epoch: [1][3800/16626] Elapsed 10m 48s (remain 36m 28s) Loss: 0.0000(0.0016) Grad: 0.0005  LR: 0.00001990  \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/root/kaggle/code/LECR_train_baseline_tricks.ipynb 单元格 31\u001b[0m in \u001b[0;36m<cell line: 8>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bi-2.gpushare.com/root/kaggle/code/LECR_train_baseline_tricks.ipynb#X44sdnNjb2RlLXJlbW90ZQ%3D%3D?line=5'>6</a>\u001b[0m tr_dataset \u001b[39m=\u001b[39m TrainDataset(tr_data,tokenizer)\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bi-2.gpushare.com/root/kaggle/code/LECR_train_baseline_tricks.ipynb#X44sdnNjb2RlLXJlbW90ZQ%3D%3D?line=6'>7</a>\u001b[0m va_dataset \u001b[39m=\u001b[39m TrainDataset(va_data,tokenizer)\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bi-2.gpushare.com/root/kaggle/code/LECR_train_baseline_tricks.ipynb#X44sdnNjb2RlLXJlbW90ZQ%3D%3D?line=7'>8</a>\u001b[0m val_result \u001b[39m=\u001b[39m train_loop(fold, model,tr_dataset, va_dataset)\n",
      "\u001b[1;32m/root/kaggle/code/LECR_train_baseline_tricks.ipynb 单元格 31\u001b[0m in \u001b[0;36mtrain_loop\u001b[0;34m(fold, model, train_dataset, valid_dataset)\u001b[0m\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2Bi-2.gpushare.com/root/kaggle/code/LECR_train_baseline_tricks.ipynb#X44sdnNjb2RlLXJlbW90ZQ%3D%3D?line=142'>143</a>\u001b[0m start_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2Bi-2.gpushare.com/root/kaggle/code/LECR_train_baseline_tricks.ipynb#X44sdnNjb2RlLXJlbW90ZQ%3D%3D?line=144'>145</a>\u001b[0m \u001b[39m# train\u001b[39;00m\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2Bi-2.gpushare.com/root/kaggle/code/LECR_train_baseline_tricks.ipynb#X44sdnNjb2RlLXJlbW90ZQ%3D%3D?line=145'>146</a>\u001b[0m \u001b[39m#avg_loss = train_fn_awp(train_loader, model, optimizer, epoch, scheduler, CFG.device)\u001b[39;00m\n\u001b[0;32m--> <a href='vscode-notebook-cell://ssh-remote%2Bi-2.gpushare.com/root/kaggle/code/LECR_train_baseline_tricks.ipynb#X44sdnNjb2RlLXJlbW90ZQ%3D%3D?line=147'>148</a>\u001b[0m avg_loss \u001b[39m=\u001b[39m train_fn(train_loader, model, optimizer, epoch, scheduler, CFG\u001b[39m.\u001b[39;49mdevice)\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2Bi-2.gpushare.com/root/kaggle/code/LECR_train_baseline_tricks.ipynb#X44sdnNjb2RlLXJlbW90ZQ%3D%3D?line=148'>149</a>\u001b[0m \u001b[39m# eval\u001b[39;00m\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2Bi-2.gpushare.com/root/kaggle/code/LECR_train_baseline_tricks.ipynb#X44sdnNjb2RlLXJlbW90ZQ%3D%3D?line=149'>150</a>\u001b[0m \u001b[39m#avg_val_loss, predictions, valid_labels = valid_fn(valid_loader, model, CFG.device)\u001b[39;00m\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2Bi-2.gpushare.com/root/kaggle/code/LECR_train_baseline_tricks.ipynb#X44sdnNjb2RlLXJlbW90ZQ%3D%3D?line=150'>151</a>\u001b[0m \n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2Bi-2.gpushare.com/root/kaggle/code/LECR_train_baseline_tricks.ipynb#X44sdnNjb2RlLXJlbW90ZQ%3D%3D?line=151'>152</a>\u001b[0m \u001b[39m# scoring\u001b[39;00m\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2Bi-2.gpushare.com/root/kaggle/code/LECR_train_baseline_tricks.ipynb#X44sdnNjb2RlLXJlbW90ZQ%3D%3D?line=152'>153</a>\u001b[0m \u001b[39m#score = get_score(predictions, valid_labels)\u001b[39;00m\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2Bi-2.gpushare.com/root/kaggle/code/LECR_train_baseline_tricks.ipynb#X44sdnNjb2RlLXJlbW90ZQ%3D%3D?line=154'>155</a>\u001b[0m elapsed \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m start_time\n",
      "\u001b[1;32m/root/kaggle/code/LECR_train_baseline_tricks.ipynb 单元格 31\u001b[0m in \u001b[0;36mtrain_fn\u001b[0;34m(train_loader, model, optimizer, epoch, scheduler, device)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bi-2.gpushare.com/root/kaggle/code/LECR_train_baseline_tricks.ipynb#X44sdnNjb2RlLXJlbW90ZQ%3D%3D?line=12'>13</a>\u001b[0m loss\u001b[39m.\u001b[39mbackward()\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bi-2.gpushare.com/root/kaggle/code/LECR_train_baseline_tricks.ipynb#X44sdnNjb2RlLXJlbW90ZQ%3D%3D?line=13'>14</a>\u001b[0m grad_norm \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mnn\u001b[39m.\u001b[39mutils\u001b[39m.\u001b[39mclip_grad_norm_(model\u001b[39m.\u001b[39mparameters(), \u001b[39m50000\u001b[39m)\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Bi-2.gpushare.com/root/kaggle/code/LECR_train_baseline_tricks.ipynb#X44sdnNjb2RlLXJlbW90ZQ%3D%3D?line=14'>15</a>\u001b[0m optimizer\u001b[39m.\u001b[39;49mstep()\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bi-2.gpushare.com/root/kaggle/code/LECR_train_baseline_tricks.ipynb#X44sdnNjb2RlLXJlbW90ZQ%3D%3D?line=15'>16</a>\u001b[0m global_step \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bi-2.gpushare.com/root/kaggle/code/LECR_train_baseline_tricks.ipynb#X44sdnNjb2RlLXJlbW90ZQ%3D%3D?line=16'>17</a>\u001b[0m scheduler\u001b[39m.\u001b[39mstep()\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/optim/lr_scheduler.py:65\u001b[0m, in \u001b[0;36m_LRScheduler.__init__.<locals>.with_counter.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m instance\u001b[39m.\u001b[39m_step_count \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m     64\u001b[0m wrapped \u001b[39m=\u001b[39m func\u001b[39m.\u001b[39m\u001b[39m__get__\u001b[39m(instance, \u001b[39mcls\u001b[39m)\n\u001b[0;32m---> 65\u001b[0m \u001b[39mreturn\u001b[39;00m wrapped(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py:109\u001b[0m, in \u001b[0;36mOptimizer._hook_for_profile.<locals>.profile_hook_step.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    107\u001b[0m profile_name \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mOptimizer.step#\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m.step\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(obj\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m)\n\u001b[1;32m    108\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mautograd\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mrecord_function(profile_name):\n\u001b[0;32m--> 109\u001b[0m     \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/transformers/optimization.py:361\u001b[0m, in \u001b[0;36mAdamW.step\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    358\u001b[0m \u001b[39m# Decay the first and second moment running average coefficient\u001b[39;00m\n\u001b[1;32m    359\u001b[0m \u001b[39m# In-place operations to update the averages at the same time\u001b[39;00m\n\u001b[1;32m    360\u001b[0m exp_avg\u001b[39m.\u001b[39mmul_(beta1)\u001b[39m.\u001b[39madd_(grad, alpha\u001b[39m=\u001b[39m(\u001b[39m1.0\u001b[39m \u001b[39m-\u001b[39m beta1))\n\u001b[0;32m--> 361\u001b[0m exp_avg_sq\u001b[39m.\u001b[39;49mmul_(beta2)\u001b[39m.\u001b[39maddcmul_(grad, grad, value\u001b[39m=\u001b[39m\u001b[39m1.0\u001b[39m \u001b[39m-\u001b[39m beta2)\n\u001b[1;32m    362\u001b[0m denom \u001b[39m=\u001b[39m exp_avg_sq\u001b[39m.\u001b[39msqrt()\u001b[39m.\u001b[39madd_(group[\u001b[39m\"\u001b[39m\u001b[39meps\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[1;32m    364\u001b[0m step_size \u001b[39m=\u001b[39m group[\u001b[39m\"\u001b[39m\u001b[39mlr\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = Custom_Bert_Simple()\n",
    "tokenizer = AutoTokenizer.from_pretrained(CFG.model_path)\n",
    "fold = 0\n",
    "tr_data = df[df['fold']!=fold].reset_index(drop=True)\n",
    "va_data = df[df['fold']==fold].reset_index(drop=True)\n",
    "tr_dataset = TrainDataset(tr_data,tokenizer)\n",
    "va_dataset = TrainDataset(va_data,tokenizer)\n",
    "val_result = train_loop(fold, model,tr_dataset, va_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_b-cAuYKG3Bg"
   },
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'hnswlib'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_19869/853224595.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mrandom\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mamp\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mautocast\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mGradScaler\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mhnswlib\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'hnswlib'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import math\n",
    "from sklearn.metrics import f1_score\n",
    "from torch.optim import Adam, SGD, AdamW\n",
    "from transformers import get_linear_schedule_with_warmup, get_cosine_schedule_with_warmup, DataCollatorWithPadding\n",
    "from transformers import BertTokenizer,AutoModel,AdamW,AutoConfig, AutoModelForSequenceClassification, AutoTokenizer\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim import lr_scheduler\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "import copy\n",
    "import torch.nn as nn\n",
    "import os\n",
    "import json\n",
    "import gc\n",
    "import random\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "import hnswlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CFG:\n",
    "    input_path = r'/root/kaggle/input_dir/'\n",
    "    model_path = r'/root/kaggle/input_dir/model/mdeberta-v3-base' \n",
    "    scheduler = 'cosine'  # ['linear', 'cosine']\n",
    "    batch_scheduler = True\n",
    "    num_cycles = 0.5  # 1.5\n",
    "    num_warmup_steps = 0\n",
    "    max_input_length = 124\n",
    "    epochs = 5  # 5\n",
    "    encoder_lr = 20e-6\n",
    "    decoder_lr = 1e-3\n",
    "    min_lr = 0.5e-6\n",
    "    eps = 1e-6\n",
    "    betas = (0.9, 0.999)\n",
    "    weight_decay = 0\n",
    "    num_fold = 5\n",
    "    batch_size = 32\n",
    "    seed = 1006\n",
    "    OUTPUT_DIR = r'/root/kaggle/output_dir/'\n",
    "    num_workers = 2\n",
    "    device='cuda'\n",
    "    print_freq = 100\n",
    "    apex=False\n",
    "    start_awp_epoch = 2 # 开始AWP epoch\n",
    "    adv_lr = 1e-5 # AWP学习率\n",
    "    adv_eps = 1e-3 # AWP epsilon\n",
    "    adv_step = 1 # AWP step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Custom_Bert_Simple(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.base = AutoModel.from_pretrained(CFG.model_path)\n",
    "        self.config = AutoConfig.from_pretrained(CFG.model_path)\n",
    "\n",
    "    def forward(self,\n",
    "        input_ids,\n",
    "        attention_mask=None):\n",
    "        output = self.base(input_ids=input_ids,attention_mask=attention_mask)\n",
    "        output = output.last_hidden_state\n",
    "        output = torch.mean(output, dim=1)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = Custom_Bert_Simple()\n",
    "# model.load_state_dict(torch.load('LECRmicrosoft_mdeberta-v3-base_best0.pth'),strict=False)\n",
    "model.to(CFG.device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "content_df = pd.read_csv(CFG.input_path + r'content.csv')\n",
    "correlations_df = pd.read_csv(CFG.input_path + r'correlations.csv')\n",
    "topics_df = pd.read_csv(CFG.input_path + r'topics.csv')\n",
    "#topics_df = topics_df[topics_df['category']!='source'].reset_index(drop=True)\n",
    "sub_df = pd.read_csv('sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(CFG.model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Testataset(Dataset):\n",
    "    def __init__(self,df,tokenizer):\n",
    "        self.title = df['title'].values\n",
    "        self.description = df['description'].values\n",
    "        self.text = None\n",
    "        if 'text' in df.columns:\n",
    "            self.text = df['text'].values\n",
    "        \n",
    "        self.tokenizer = tokenizer\n",
    "        self.sep_token = tokenizer.sep_token\n",
    "    def __len__(self):\n",
    "        return len(self.title)\n",
    "    def __getitem__(self, item):\n",
    "        \n",
    "        input_text = self.title[item]\n",
    "        if isinstance(input_text, float):\n",
    "            input_text = ''\n",
    "        if not isinstance(self.description[item], float):\n",
    "            #print(self.description[item])\n",
    "            input_text += ' ' + self.sep_token + ' ' + self.description[item]\n",
    "        \n",
    "        if self.text is not None and not isinstance(self.text[item], float):\n",
    "            input_text += ' ' + self.sep_token + self.text[item]\n",
    "            \n",
    "        output = self.tokenizer(input_text, truncation=True, max_length=CFG.max_input_length, padding='max_length')\n",
    "        \n",
    "        return torch.as_tensor(output['input_ids'], dtype=torch.long), \\\n",
    "            torch.as_tensor(output['attention_mask'], dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_dataset = Testataset(topics_df[topics_df['id'].isin(sub_df['topic_id'])], tokenizer)\n",
    "content_dataset = Testataset(content_df, tokenizer)\n",
    "topic_loader = DataLoader(topic_dataset,\n",
    "                              batch_size=CFG.batch_size * 2,\n",
    "                              shuffle=False,\n",
    "                              num_workers=CFG.num_workers, pin_memory=True, drop_last=False)\n",
    "content_loader = DataLoader(content_dataset,\n",
    "                              batch_size=CFG.batch_size * 2,\n",
    "                              shuffle=False,\n",
    "                              num_workers=CFG.num_workers, pin_memory=True, drop_last=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def infer(model, dataloader):\n",
    "    res = []\n",
    "    for batch in tqdm(dataloader):\n",
    "        input_ids, attention_mask = [i.to(CFG.device) for i in batch]\n",
    "        with torch.no_grad():\n",
    "            output = model(input_ids, attention_mask)\n",
    "            res.append(output.cpu().numpy())\n",
    "    \n",
    "    return np.vstack(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  2.51it/s]\n"
     ]
    }
   ],
   "source": [
    "topic_result = infer(model, topic_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2407/2407 [12:43<00:00,  3.15it/s]\n"
     ]
    }
   ],
   "source": [
    "content_result = infer(model, content_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "content_ids = [i for i in range(len(content_df))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_index(embeddings, ids):\n",
    "\n",
    "    index = hnswlib.Index(space=\"cosine\", dim=embeddings.shape[-1])\n",
    "\n",
    "    # Initializing index\n",
    "    # max_elements - the maximum number of elements (capacity). Will throw an exception if exceeded\n",
    "    # during insertion of an element.\n",
    "    # The capacity can be increased by saving/loading the index, see below.\n",
    "    #\n",
    "    # ef_construction - controls index search speed/build speed tradeoff\n",
    "    #\n",
    "    # M - is tightly connected with internal dimensionality of the data. Strongly affects memory consumption (~M)\n",
    "    # Higher M leads to higher accuracy/run_time at fixed ef/efConstruction\n",
    "    index.init_index(max_elements=embeddings.shape[0], ef_construction=200, M=160)\n",
    "\n",
    "    # Controlling the recall by setting ef:\n",
    "    # higher ef leads to better accuracy, but slower search\n",
    "    index.set_ef(50)\n",
    "\n",
    "    # Set number of threads used during batch search/construction\n",
    "    # By default using all available cores\n",
    "    index.set_num_threads(16)\n",
    "\n",
    "    \n",
    "    index.add_items(embeddings, ids)\n",
    "\n",
    "\n",
    "    return index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "content_index = build_index(content_result, content_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = content_index.knn_query(topic_result, k = 5, num_threads = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00, 107.23it/s]\n"
     ]
    }
   ],
   "source": [
    "pred = []\n",
    "conten_uid = content_df['id']\n",
    "for result in tqdm(results[0]):\n",
    "    top_same = ' '.join(conten_uid[result].to_list())\n",
    "    pred.append(top_same)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c_9d61ca64065c c_7c38160748ad c_b922de5db068 c_5c0cfe8772fe c_88b54048c6ae'"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic_id</th>\n",
       "      <th>content_ids</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>t_00004da3a1b2</td>\n",
       "      <td>c_9d61ca64065c c_7c38160748ad c_b922de5db068 c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>t_00068291e9a4</td>\n",
       "      <td>c_207bb2e7346f c_42c8b513508c c_3a9fabe1f4e0 c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>t_00069b63a70a</td>\n",
       "      <td>c_487defefd442 c_b7e629d2a6d0 c_74fc8d315563 c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>t_0006d41a73a8</td>\n",
       "      <td>c_96c5ae7cd9f9 c_aaac446c7b8b c_6953a88de9f6 c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>t_4054df11a74e</td>\n",
       "      <td>c_542e610aa1e1 c_4cc5d89eb9e3 c_2fc11e484b99 c...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         topic_id                                        content_ids\n",
       "0  t_00004da3a1b2  c_9d61ca64065c c_7c38160748ad c_b922de5db068 c...\n",
       "1  t_00068291e9a4  c_207bb2e7346f c_42c8b513508c c_3a9fabe1f4e0 c...\n",
       "2  t_00069b63a70a  c_487defefd442 c_b7e629d2a6d0 c_74fc8d315563 c...\n",
       "3  t_0006d41a73a8  c_96c5ae7cd9f9 c_aaac446c7b8b c_6953a88de9f6 c...\n",
       "4  t_4054df11a74e  c_542e610aa1e1 c_4cc5d89eb9e3 c_2fc11e484b99 c..."
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub_df['content_ids'] = pred\n",
    "sub_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_df.to_csv(CFG.OUTPUT_DIR + r'submission.csv', index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
