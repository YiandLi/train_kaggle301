{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "XfVCwUiETLWX"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedGroupKFold\n",
    "from multiprocesspandas import applyparallel\n",
    "from tqdm import tqdm\n",
    "from transformers import AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "KpzDtQBUUCd1"
   },
   "outputs": [],
   "source": [
    "input_dir = '/root/kaggle/input_dir/'\n",
    "topic_df = pd.read_csv(input_dir + 'topics.csv')\n",
    "content_df = pd.read_csv(input_dir + 'content.csv')\n",
    "corr_df = pd.read_csv(input_dir + 'correlations.csv')\n",
    "# topic_df = topic_df.rename(columns={'id': 'topic_id'}).merge(corr_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "e9L5F7uqWhpl"
   },
   "outputs": [],
   "source": [
    "corr_df['content_ids'] = corr_df['content_ids'].apply(lambda x:x.split())\n",
    "corr_df = corr_df.explode('content_ids').reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "r94vw5-gXHoX"
   },
   "outputs": [],
   "source": [
    "topic_df = topic_df.fillna('')\n",
    "topic_df['topic_full_text'] =  topic_df['title'] + ' [SEP] ' + topic_df['description']\n",
    "topic_df = topic_df[['id', 'topic_full_text', 'language']]\n",
    "df = corr_df.merge(topic_df, left_on='topic_id', right_on='id', how='left')\n",
    "df = df[['topic_id','content_ids','topic_full_text','language']]\n",
    "df = df.rename(columns={'language':'topic_language'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "DA20jcVaXkkP"
   },
   "outputs": [],
   "source": [
    "content_df = content_df.fillna('')\n",
    "content_df['content_full_text'] =  content_df['title'] + ' [SEP] ' + content_df['description'] + ' [SEP] ' + content_df['text']\n",
    "content_df = content_df[['id', 'content_full_text', 'language']]\n",
    "df = df.merge(content_df, left_on='content_ids', right_on='id', how='left')\n",
    "df = df.rename(columns={'language':'content_language'})\n",
    "df['label'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic_id</th>\n",
       "      <th>content_ids</th>\n",
       "      <th>topic_full_text</th>\n",
       "      <th>topic_language</th>\n",
       "      <th>id</th>\n",
       "      <th>content_full_text</th>\n",
       "      <th>content_language</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>t_00004da3a1b2</td>\n",
       "      <td>c_1108dd0c7a5d</td>\n",
       "      <td>Откриването на резисторите [SEP] Изследване на...</td>\n",
       "      <td>bg</td>\n",
       "      <td>c_1108dd0c7a5d</td>\n",
       "      <td>Молив като резистор [SEP] Моливът причинява пр...</td>\n",
       "      <td>bg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>t_00004da3a1b2</td>\n",
       "      <td>c_376c5a8eb028</td>\n",
       "      <td>Откриването на резисторите [SEP] Изследване на...</td>\n",
       "      <td>bg</td>\n",
       "      <td>c_376c5a8eb028</td>\n",
       "      <td>Да чуем променливото съпротивление [SEP] Тук ч...</td>\n",
       "      <td>bg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>t_00004da3a1b2</td>\n",
       "      <td>c_5bc0e1e2cba0</td>\n",
       "      <td>Откриването на резисторите [SEP] Изследване на...</td>\n",
       "      <td>bg</td>\n",
       "      <td>c_5bc0e1e2cba0</td>\n",
       "      <td>Променлив резистор (реостат) с графит от молив...</td>\n",
       "      <td>bg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>t_00004da3a1b2</td>\n",
       "      <td>c_76231f9d0b5e</td>\n",
       "      <td>Откриването на резисторите [SEP] Изследване на...</td>\n",
       "      <td>bg</td>\n",
       "      <td>c_76231f9d0b5e</td>\n",
       "      <td>Последователно свързване на галваничен елемент...</td>\n",
       "      <td>bg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>t_00068291e9a4</td>\n",
       "      <td>c_639ea2ef9c95</td>\n",
       "      <td>Entradas e saídas de uma função [SEP] Entenda ...</td>\n",
       "      <td>pt</td>\n",
       "      <td>c_639ea2ef9c95</td>\n",
       "      <td>Dados e resultados de funções: gráficos [SEP] ...</td>\n",
       "      <td>pt</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         topic_id     content_ids  \\\n",
       "0  t_00004da3a1b2  c_1108dd0c7a5d   \n",
       "1  t_00004da3a1b2  c_376c5a8eb028   \n",
       "2  t_00004da3a1b2  c_5bc0e1e2cba0   \n",
       "3  t_00004da3a1b2  c_76231f9d0b5e   \n",
       "4  t_00068291e9a4  c_639ea2ef9c95   \n",
       "\n",
       "                                     topic_full_text topic_language  \\\n",
       "0  Откриването на резисторите [SEP] Изследване на...             bg   \n",
       "1  Откриването на резисторите [SEP] Изследване на...             bg   \n",
       "2  Откриването на резисторите [SEP] Изследване на...             bg   \n",
       "3  Откриването на резисторите [SEP] Изследване на...             bg   \n",
       "4  Entradas e saídas de uma função [SEP] Entenda ...             pt   \n",
       "\n",
       "               id                                  content_full_text  \\\n",
       "0  c_1108dd0c7a5d  Молив като резистор [SEP] Моливът причинява пр...   \n",
       "1  c_376c5a8eb028  Да чуем променливото съпротивление [SEP] Тук ч...   \n",
       "2  c_5bc0e1e2cba0  Променлив резистор (реостат) с графит от молив...   \n",
       "3  c_76231f9d0b5e  Последователно свързване на галваничен елемент...   \n",
       "4  c_639ea2ef9c95  Dados e resultados de funções: gráficos [SEP] ...   \n",
       "\n",
       "  content_language  label  \n",
       "0               bg      1  \n",
       "1               bg      1  \n",
       "2               bg      1  \n",
       "3               bg      1  \n",
       "4               pt      1  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iO0Hdds1n7_-"
   },
   "source": [
    "## random sample according to language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2Ae5YOFOh4AF",
    "outputId": "c8e5b398-9cac-4874-af8d-4dd212dff70e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/convert_slow_tokenizer.py:446: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
      "  warnings.warn(\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "  0%|          | 8/61517 [00:03<6:25:36,  2.66it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/root/kaggle/code/LECR_negative_smaple.ipynb 单元格 8\u001b[0m in \u001b[0;36m<cell line: 12>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bi-2.gpushare.com/root/kaggle/code/LECR_negative_smaple.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=19'>20</a>\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m sub_df[\u001b[39m'\u001b[39m\u001b[39mtopic_full_text\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mto_list():\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bi-2.gpushare.com/root/kaggle/code/LECR_negative_smaple.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=20'>21</a>\u001b[0m     sample_nums \u001b[39m=\u001b[39m \u001b[39mmin\u001b[39m(\u001b[39mlen\u001b[39m(candidates_same_language),sample_from_same_lamguage)\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Bi-2.gpushare.com/root/kaggle/code/LECR_negative_smaple.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=21'>22</a>\u001b[0m     sample_neg \u001b[39m=\u001b[39m candidates_same_language[[\u001b[39m'\u001b[39;49m\u001b[39mtopic_full_text\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mcontent_full_text\u001b[39;49m\u001b[39m'\u001b[39;49m]]\u001b[39m.\u001b[39msample(n\u001b[39m=\u001b[39msample_nums)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bi-2.gpushare.com/root/kaggle/code/LECR_negative_smaple.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=22'>23</a>\u001b[0m     sample_neg \u001b[39m=\u001b[39m sample_neg[\u001b[39m-\u001b[39m(sample_neg[\u001b[39m'\u001b[39m\u001b[39mcontent_full_text\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39misin(sub_df[\u001b[39m'\u001b[39m\u001b[39mcontent_full_text\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mto_list()))]\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bi-2.gpushare.com/root/kaggle/code/LECR_negative_smaple.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=23'>24</a>\u001b[0m     sample_neg[\u001b[39m'\u001b[39m\u001b[39mtopic_id\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m topic_id\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/core/frame.py:3517\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3514\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mgetattr\u001b[39m(indexer, \u001b[39m\"\u001b[39m\u001b[39mdtype\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m) \u001b[39m==\u001b[39m \u001b[39mbool\u001b[39m:\n\u001b[1;32m   3515\u001b[0m     indexer \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mwhere(indexer)[\u001b[39m0\u001b[39m]\n\u001b[0;32m-> 3517\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_take_with_is_copy(indexer, axis\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m)\n\u001b[1;32m   3519\u001b[0m \u001b[39mif\u001b[39;00m is_single_key:\n\u001b[1;32m   3520\u001b[0m     \u001b[39m# What does looking for a single key in a non-unique index return?\u001b[39;00m\n\u001b[1;32m   3521\u001b[0m     \u001b[39m# The behavior is inconsistent. It returns a Series, except when\u001b[39;00m\n\u001b[1;32m   3522\u001b[0m     \u001b[39m# - the key itself is repeated (test on data.shape, #9519), or\u001b[39;00m\n\u001b[1;32m   3523\u001b[0m     \u001b[39m# - we have a MultiIndex on columns (test on self.columns, #21309)\u001b[39;00m\n\u001b[1;32m   3524\u001b[0m     \u001b[39mif\u001b[39;00m data\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m] \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns, MultiIndex):\n\u001b[1;32m   3525\u001b[0m         \u001b[39m# GH#26490 using data[key] can cause RecursionError\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/core/generic.py:3716\u001b[0m, in \u001b[0;36mNDFrame._take_with_is_copy\u001b[0;34m(self, indices, axis)\u001b[0m\n\u001b[1;32m   3708\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_take_with_is_copy\u001b[39m(\u001b[39mself\u001b[39m: NDFrameT, indices, axis\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m NDFrameT:\n\u001b[1;32m   3709\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   3710\u001b[0m \u001b[39m    Internal version of the `take` method that sets the `_is_copy`\u001b[39;00m\n\u001b[1;32m   3711\u001b[0m \u001b[39m    attribute to keep track of the parent dataframe (using in indexing\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3714\u001b[0m \u001b[39m    See the docstring of `take` for full explanation of the parameters.\u001b[39;00m\n\u001b[1;32m   3715\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 3716\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtake(indices\u001b[39m=\u001b[39;49mindices, axis\u001b[39m=\u001b[39;49maxis)\n\u001b[1;32m   3717\u001b[0m     \u001b[39m# Maybe set copy if we didn't actually change the index.\u001b[39;00m\n\u001b[1;32m   3718\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m result\u001b[39m.\u001b[39m_get_axis(axis)\u001b[39m.\u001b[39mequals(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_axis(axis)):\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/core/generic.py:3703\u001b[0m, in \u001b[0;36mNDFrame.take\u001b[0;34m(self, indices, axis, is_copy, **kwargs)\u001b[0m\n\u001b[1;32m   3699\u001b[0m nv\u001b[39m.\u001b[39mvalidate_take((), kwargs)\n\u001b[1;32m   3701\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_consolidate_inplace()\n\u001b[0;32m-> 3703\u001b[0m new_data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_mgr\u001b[39m.\u001b[39;49mtake(\n\u001b[1;32m   3704\u001b[0m     indices, axis\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_block_manager_axis(axis), verify\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m\n\u001b[1;32m   3705\u001b[0m )\n\u001b[1;32m   3706\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_constructor(new_data)\u001b[39m.\u001b[39m__finalize__(\u001b[39mself\u001b[39m, method\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mtake\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/core/internals/managers.py:900\u001b[0m, in \u001b[0;36mBaseBlockManager.take\u001b[0;34m(self, indexer, axis, verify)\u001b[0m\n\u001b[1;32m    897\u001b[0m indexer \u001b[39m=\u001b[39m maybe_convert_indices(indexer, n, verify\u001b[39m=\u001b[39mverify)\n\u001b[1;32m    899\u001b[0m new_labels \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maxes[axis]\u001b[39m.\u001b[39mtake(indexer)\n\u001b[0;32m--> 900\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mreindex_indexer(\n\u001b[1;32m    901\u001b[0m     new_axis\u001b[39m=\u001b[39;49mnew_labels,\n\u001b[1;32m    902\u001b[0m     indexer\u001b[39m=\u001b[39;49mindexer,\n\u001b[1;32m    903\u001b[0m     axis\u001b[39m=\u001b[39;49maxis,\n\u001b[1;32m    904\u001b[0m     allow_dups\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m    905\u001b[0m     consolidate\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    906\u001b[0m )\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/core/internals/managers.py:685\u001b[0m, in \u001b[0;36mBaseBlockManager.reindex_indexer\u001b[0;34m(self, new_axis, indexer, axis, fill_value, allow_dups, copy, consolidate, only_slice, use_na_proxy)\u001b[0m\n\u001b[1;32m    682\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mIndexError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mRequested axis not found in manager\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    684\u001b[0m \u001b[39mif\u001b[39;00m axis \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m--> 685\u001b[0m     new_blocks \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_slice_take_blocks_ax0(\n\u001b[1;32m    686\u001b[0m         indexer,\n\u001b[1;32m    687\u001b[0m         fill_value\u001b[39m=\u001b[39;49mfill_value,\n\u001b[1;32m    688\u001b[0m         only_slice\u001b[39m=\u001b[39;49monly_slice,\n\u001b[1;32m    689\u001b[0m         use_na_proxy\u001b[39m=\u001b[39;49muse_na_proxy,\n\u001b[1;32m    690\u001b[0m     )\n\u001b[1;32m    691\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    692\u001b[0m     new_blocks \u001b[39m=\u001b[39m [\n\u001b[1;32m    693\u001b[0m         blk\u001b[39m.\u001b[39mtake_nd(\n\u001b[1;32m    694\u001b[0m             indexer,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    700\u001b[0m         \u001b[39mfor\u001b[39;00m blk \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mblocks\n\u001b[1;32m    701\u001b[0m     ]\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/core/internals/managers.py:844\u001b[0m, in \u001b[0;36mBaseBlockManager._slice_take_blocks_ax0\u001b[0;34m(self, slice_or_indexer, fill_value, only_slice, use_na_proxy)\u001b[0m\n\u001b[1;32m    842\u001b[0m                     blocks\u001b[39m.\u001b[39mappend(nb)\n\u001b[1;32m    843\u001b[0m             \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 844\u001b[0m                 nb \u001b[39m=\u001b[39m blk\u001b[39m.\u001b[39;49mtake_nd(taker, axis\u001b[39m=\u001b[39;49m\u001b[39m0\u001b[39;49m, new_mgr_locs\u001b[39m=\u001b[39;49mmgr_locs)\n\u001b[1;32m    845\u001b[0m                 blocks\u001b[39m.\u001b[39mappend(nb)\n\u001b[1;32m    847\u001b[0m \u001b[39mreturn\u001b[39;00m blocks\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/core/internals/blocks.py:1139\u001b[0m, in \u001b[0;36mBlock.take_nd\u001b[0;34m(self, indexer, axis, new_mgr_locs, fill_value)\u001b[0m\n\u001b[1;32m   1136\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1137\u001b[0m     allow_fill \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m-> 1139\u001b[0m new_values \u001b[39m=\u001b[39m algos\u001b[39m.\u001b[39;49mtake_nd(\n\u001b[1;32m   1140\u001b[0m     values, indexer, axis\u001b[39m=\u001b[39;49maxis, allow_fill\u001b[39m=\u001b[39;49mallow_fill, fill_value\u001b[39m=\u001b[39;49mfill_value\n\u001b[1;32m   1141\u001b[0m )\n\u001b[1;32m   1143\u001b[0m \u001b[39m# Called from three places in managers, all of which satisfy\u001b[39;00m\n\u001b[1;32m   1144\u001b[0m \u001b[39m#  this assertion\u001b[39;00m\n\u001b[1;32m   1145\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mnot\u001b[39;00m (axis \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m \u001b[39mand\u001b[39;00m new_mgr_locs \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/core/array_algos/take.py:117\u001b[0m, in \u001b[0;36mtake_nd\u001b[0;34m(arr, indexer, axis, fill_value, allow_fill)\u001b[0m\n\u001b[1;32m    114\u001b[0m     \u001b[39mreturn\u001b[39;00m arr\u001b[39m.\u001b[39mtake(indexer, fill_value\u001b[39m=\u001b[39mfill_value, allow_fill\u001b[39m=\u001b[39mallow_fill)\n\u001b[1;32m    116\u001b[0m arr \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39masarray(arr)\n\u001b[0;32m--> 117\u001b[0m \u001b[39mreturn\u001b[39;00m _take_nd_ndarray(arr, indexer, axis, fill_value, allow_fill)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/core/array_algos/take.py:163\u001b[0m, in \u001b[0;36m_take_nd_ndarray\u001b[0;34m(arr, indexer, axis, fill_value, allow_fill)\u001b[0m\n\u001b[1;32m    158\u001b[0m     out \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mempty(out_shape, dtype\u001b[39m=\u001b[39mdtype)\n\u001b[1;32m    160\u001b[0m func \u001b[39m=\u001b[39m _get_take_nd_function(\n\u001b[1;32m    161\u001b[0m     arr\u001b[39m.\u001b[39mndim, arr\u001b[39m.\u001b[39mdtype, out\u001b[39m.\u001b[39mdtype, axis\u001b[39m=\u001b[39maxis, mask_info\u001b[39m=\u001b[39mmask_info\n\u001b[1;32m    162\u001b[0m )\n\u001b[0;32m--> 163\u001b[0m func(arr, indexer, out, fill_value)\n\u001b[1;32m    165\u001b[0m \u001b[39mif\u001b[39;00m flip_order:\n\u001b[1;32m    166\u001b[0m     out \u001b[39m=\u001b[39m out\u001b[39m.\u001b[39mT\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "neg_df = []\n",
    "sample_n = 20\n",
    "sample_from_same_lamguage  = 16\n",
    "path = r'/root/kaggle/input_dir/model/mdeberta-v3-base'\n",
    "tokenizer = AutoTokenizer.from_pretrained(path)\n",
    "def negative_smaple(x, candidates):\n",
    "    topic_language = x['topic_language'][0]\n",
    "    candidates = candidates[candidates['content_language'] == topic_language]\n",
    "    return candidates[['topic_full_text', 'content_full_text']].sample(n=sample_n)\n",
    "\n",
    "\n",
    "for topic_id in tqdm(df['topic_id'].unique()):\n",
    "    sub_df = df[df['topic_id'] == topic_id]\n",
    "    topic_language = sub_df['topic_language'].unique()[0]\n",
    "    topic_full_text = sub_df['topic_full_text'].unique()[0]\n",
    "    candidates_same_language = df[df['content_language'] == topic_language]\n",
    "    candidates_diff_language = df[df['content_language'] != topic_language]\n",
    "    ## random same language negative sample\n",
    "    random_same_language = []\n",
    "    for i in sub_df['topic_full_text'].to_list():\n",
    "        sample_nums = min(len(candidates_same_language),sample_from_same_lamguage)\n",
    "        sample_neg = candidates_same_language[['topic_full_text', 'content_full_text']].sample(n=sample_nums)\n",
    "        sample_neg = sample_neg[-(sample_neg['content_full_text'].isin(sub_df['content_full_text'].to_list()))]\n",
    "        sample_neg['topic_id'] = topic_id\n",
    "        sample_neg['label'] = 0\n",
    "        sample_neg['topic_full_text'] = i\n",
    "        random_same_language.append(sample_neg)\n",
    "    \n",
    "    #random other language negative sample\n",
    "    \n",
    "    random_diff_language = []\n",
    "    for i in sub_df['topic_full_text'].to_list():\n",
    "        sample_nums = min(len(candidates_diff_language),sample_n - sample_from_same_lamguage)\n",
    "        sample_neg = candidates_diff_language[['topic_full_text', 'content_full_text']].sample(n=sample_n - sample_from_same_lamguage)\n",
    "        sample_neg = sample_neg[-(sample_neg['content_full_text'].isin(sub_df['content_full_text'].to_list()))]\n",
    "        sample_neg['topic_id'] = topic_id\n",
    "        sample_neg['label'] = 0\n",
    "        sample_neg['topic_full_text'] = i\n",
    "        random_diff_language.append(sample_neg)\n",
    "    random_same_language = pd.concat(random_same_language)\n",
    "    random_diff_language = pd.concat(random_diff_language)\n",
    "    neg_df.append(random_same_language)\n",
    "    neg_df.append(random_diff_language)\n",
    "\n",
    "neg_df = pd.concat(neg_df)\n",
    "neg_df = neg_df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic_full_text</th>\n",
       "      <th>content_full_text</th>\n",
       "      <th>topic_id</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>215841</th>\n",
       "      <td>Откриването на резисторите [SEP] Изследване на...</td>\n",
       "      <td>Отношения, представени с лентови диаграми [SEP...</td>\n",
       "      <td>t_00004da3a1b2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101092</th>\n",
       "      <td>Откриването на резисторите [SEP] Изследване на...</td>\n",
       "      <td>Ъгли - основни понятия [SEP] Определи кой ъгъл...</td>\n",
       "      <td>t_00004da3a1b2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250766</th>\n",
       "      <td>Откриването на резисторите [SEP] Изследване на...</td>\n",
       "      <td>Умножение на две обикновени дроби с помощта на...</td>\n",
       "      <td>t_00004da3a1b2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103993</th>\n",
       "      <td>Откриването на резисторите [SEP] Изследване на...</td>\n",
       "      <td>Последователно свързани резистори [SEP] Резист...</td>\n",
       "      <td>t_00004da3a1b2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49535</th>\n",
       "      <td>Откриването на резисторите [SEP] Изследване на...</td>\n",
       "      <td>Артериолосклероза - част 2 [SEP] Виж как хипер...</td>\n",
       "      <td>t_00004da3a1b2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194656</th>\n",
       "      <td>تحديد العلاقة بين الإحداثيّات القطبية والإحداث...</td>\n",
       "      <td>7. المتغيرات [SEP]  [SEP]</td>\n",
       "      <td>t_fffe811a6da9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67934</th>\n",
       "      <td>تحديد العلاقة بين الإحداثيّات القطبية والإحداث...</td>\n",
       "      <td>Level 2 : Remainder and factor theorem [SEP]  ...</td>\n",
       "      <td>t_fffe811a6da9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203306</th>\n",
       "      <td>تحديد العلاقة بين الإحداثيّات القطبية والإحداث...</td>\n",
       "      <td>Problemas de subtração até 10 [SEP] Sal resolv...</td>\n",
       "      <td>t_fffe811a6da9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165147</th>\n",
       "      <td>تحديد العلاقة بين الإحداثيّات القطبية والإحداث...</td>\n",
       "      <td>Tatouage Henné : Motif Simple 4-9 [SEP]  [SEP]...</td>\n",
       "      <td>t_fffe811a6da9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10158</th>\n",
       "      <td>تحديد العلاقة بين الإحداثيّات القطبية والإحداث...</td>\n",
       "      <td>Level 2: The Meanings of Division [SEP] v0.1 [...</td>\n",
       "      <td>t_fffe811a6da9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5492666 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          topic_full_text  \\\n",
       "215841  Откриването на резисторите [SEP] Изследване на...   \n",
       "101092  Откриването на резисторите [SEP] Изследване на...   \n",
       "250766  Откриването на резисторите [SEP] Изследване на...   \n",
       "103993  Откриването на резисторите [SEP] Изследване на...   \n",
       "49535   Откриването на резисторите [SEP] Изследване на...   \n",
       "...                                                   ...   \n",
       "194656  تحديد العلاقة بين الإحداثيّات القطبية والإحداث...   \n",
       "67934   تحديد العلاقة بين الإحداثيّات القطبية والإحداث...   \n",
       "203306  تحديد العلاقة بين الإحداثيّات القطبية والإحداث...   \n",
       "165147  تحديد العلاقة بين الإحداثيّات القطبية والإحداث...   \n",
       "10158   تحديد العلاقة بين الإحداثيّات القطبية والإحداث...   \n",
       "\n",
       "                                        content_full_text        topic_id  \\\n",
       "215841  Отношения, представени с лентови диаграми [SEP...  t_00004da3a1b2   \n",
       "101092  Ъгли - основни понятия [SEP] Определи кой ъгъл...  t_00004da3a1b2   \n",
       "250766  Умножение на две обикновени дроби с помощта на...  t_00004da3a1b2   \n",
       "103993  Последователно свързани резистори [SEP] Резист...  t_00004da3a1b2   \n",
       "49535   Артериолосклероза - част 2 [SEP] Виж как хипер...  t_00004da3a1b2   \n",
       "...                                                   ...             ...   \n",
       "194656                         7. المتغيرات [SEP]  [SEP]   t_fffe811a6da9   \n",
       "67934   Level 2 : Remainder and factor theorem [SEP]  ...  t_fffe811a6da9   \n",
       "203306  Problemas de subtração até 10 [SEP] Sal resolv...  t_fffe811a6da9   \n",
       "165147  Tatouage Henné : Motif Simple 4-9 [SEP]  [SEP]...  t_fffe811a6da9   \n",
       "10158   Level 2: The Meanings of Division [SEP] v0.1 [...  t_fffe811a6da9   \n",
       "\n",
       "        label  \n",
       "215841      0  \n",
       "101092      0  \n",
       "250766      0  \n",
       "103993      0  \n",
       "49535       0  \n",
       "...       ...  \n",
       "194656      0  \n",
       "67934       0  \n",
       "203306      0  \n",
       "165147      0  \n",
       "10158       0  \n",
       "\n",
       "[5492666 rows x 4 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neg_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_df.to_parquet('random_negative_for_recall_exp4.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "5b3ded1ccb95c1d9bd405e7b823d9e85424cde40fbb5985eb47e999ef50e15b4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
